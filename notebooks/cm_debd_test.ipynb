{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3e5b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "repo_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(repo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ac459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.bins_samplers import GaussianQMCSampler\n",
    "from models.cm import ContinuousMixture\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.datasets import load_debd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "gpus = None if device == 'cpu' else 1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8632e372",
   "metadata": {},
   "source": [
    "### Specify the datasets to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBD_DATASETS = [\n",
    "    'nltcs',\n",
    "    'msnbc',\n",
    "    'kdd',\n",
    "    'plants',\n",
    "    'baudio',\n",
    "    'jester',\n",
    "    'bnetflix',\n",
    "    'accidents',\n",
    "    'tretail',\n",
    "    'pumsb_star',\n",
    "    'dna',\n",
    "    'kosarek',\n",
    "    'msweb',\n",
    "    'book',\n",
    "    'tmovie',\n",
    "    'cwebkb',\n",
    "    'cr52',\n",
    "    'c20ng',\n",
    "    'bbc',\n",
    "    'ad',\n",
    "]\n",
    "print(DEBD_DATASETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbb4965",
   "metadata": {},
   "source": [
    "### Number of integration points (bins) to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cbd151",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins_list = [2**7, 2**8, 2**9, 2**10, 2**11, 2**12, 2**13]\n",
    "print(n_bins_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8289a9ac",
   "metadata": {},
   "source": [
    "### Set clt to False (True) for CM of factorisations (of CLTs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clt = True\n",
    "log_dir = repo_dir + ('/logs/debd/cm_clt/' if clt else '/logs/debd/cm_fact/')\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e258a620",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939fed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lls_dict(lls_dict):\n",
    "    for n_bins in lls_dict.keys():\n",
    "        avg_lls_per_run = [np.mean(ll) for ll in lls_dict[n_bins]]\n",
    "        avg_ll = np.mean(avg_lls_per_run)\n",
    "        std_ll = np.std(avg_lls_per_run)\n",
    "        print('Evaluating using ' + str(n_bins) + ' bins..')\n",
    "        print('AVG LL: %f ' % avg_ll + ' STD LL: %f ' % std_ll)\n",
    "        print('Latex string: %.2f$\\\\pm$%.2f' % (avg_ll, std_ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dcfa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you run OOM you can tweak n_chunks and batch_size\n",
    "only_test = True\n",
    "n_chunks = None\n",
    "batch_size = 32\n",
    "\n",
    "for dataset_name in DEBD_DATASETS:\n",
    "    \n",
    "    _, valid, test = load_debd(dataset_name)\n",
    "    valid_loader = DataLoader(valid, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size)\n",
    "    print('Evaluating ' + dataset_name + '..')\n",
    "\n",
    "    if not only_test:\n",
    "        bmv_valid_lls_dict = {n_bins: [] for n_bins in n_bins_list}\n",
    "    bmv_test_lls_dict = {n_bins: [] for n_bins in n_bins_list}\n",
    "        \n",
    "    exp_runs = 0\n",
    "    folder_tree = list(os.walk(log_dir + dataset_name))\n",
    "    for folder in folder_tree:\n",
    "        \n",
    "        if 'checkpoints' in folder[0]:\n",
    "            exp_runs += 1\n",
    "            for ckpt in folder[2]:\n",
    "                model = ContinuousMixture.load_from_checkpoint(folder[0] + '/' + ckpt).to(device)\n",
    "                model.n_chunks = n_chunks\n",
    "                model.missing = False\n",
    "                for n_bins in n_bins_list:\n",
    "                    test_sampler = GaussianQMCSampler(latent_dim=4, n_bins=n_bins)\n",
    "                    z, log_w = test_sampler(seed=42)\n",
    "                    if 'best_model_valid' in ckpt:\n",
    "                        if not only_test:\n",
    "                            bmv_valid_lls_dict[n_bins].append(\n",
    "                                model.eval_loader(valid_loader, z, log_w, device=device).cpu().numpy())\n",
    "                        bmv_test_lls_dict[n_bins].append(\n",
    "                            model.eval_loader(test_loader, z, log_w, device=device).cpu().numpy())\n",
    "    \n",
    "    if not only_test:\n",
    "        print('\\n --- BMV on VALID ---')\n",
    "        evaluate_lls_dict(bmv_valid_lls_dict)\n",
    "    print('\\n --- BMV on TEST ---')\n",
    "    evaluate_lls_dict(bmv_test_lls_dict)\n",
    "    \n",
    "    print('\\n' + str(exp_runs) + ' runs found and evaluated for ' + dataset_name + '\\n\\n')\n",
    "    print('---------------------------------------------------------------------------\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
