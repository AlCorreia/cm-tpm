{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4362ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "repo_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(repo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.bins_samplers import GaussianQMCSampler\n",
    "from utils.reproducibility import seed_everything\n",
    "from models.mixtures import BernoulliMixture\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.datasets import load_debd\n",
    "import pytorch_lightning as pl\n",
    "from models.vae import VAE\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "gpus = None if device == 'cpu' else 1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76dc565",
   "metadata": {},
   "source": [
    "## Specify the datasets to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bbf08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BINARY_DATASETS = [\n",
    "    'nltcs',\n",
    "    'msnbc',\n",
    "    'kdd',\n",
    "    'plants',\n",
    "    'baudio',\n",
    "    'jester',\n",
    "    'bnetflix',\n",
    "    'accidents',\n",
    "    'tretail',\n",
    "    'pumsb_star',\n",
    "    'dna',\n",
    "    'kosarek',\n",
    "    'msweb',\n",
    "    'book',\n",
    "    'tmovie',\n",
    "    'cwebkb',\n",
    "    'cr52',\n",
    "    'c20ng',\n",
    "    'bbc',\n",
    "    'ad',\n",
    "]\n",
    "print(BINARY_DATASETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38b80a5",
   "metadata": {},
   "source": [
    "## Specify the integration points (bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins_list = [2**7, 2**8, 2**9, 2**10, 2**11, 2**12, 2**13]\n",
    "keys = ['elbo'] + n_bins_list\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = GaussianQMCSampler(latent_dim=4, n_bins=n_bins_list[0])\n",
    "\n",
    "def evaluate_mixture(model, loader, z, log_w, device):\n",
    "    logits_p = model.vae.decoder(z.to(device)).logit()\n",
    "    mixture = BernoulliMixture(logits_p=logits_p, logits_w=log_w).to(device)\n",
    "    lls = []\n",
    "    for x in loader:\n",
    "        lls.extend(list(mixture(x.to(device)).detach().cpu().numpy()))\n",
    "    assert len(lls) == len(loader.dataset)\n",
    "    return lls\n",
    "\n",
    "def evaluate_elbo(model, loader, n_mc_samples, device):\n",
    "    lls = []\n",
    "    model.eval();\n",
    "    for x in loader:\n",
    "        lls.extend(model.log_prob(x.to(device), n_mc_samples).detach().cpu().numpy())\n",
    "    assert len(lls) == len(loader.dataset)\n",
    "    return lls\n",
    "\n",
    "def evaluate_lls_dict(lls_dict):\n",
    "    for key in lls_dict.keys():\n",
    "        avg_lls_per_run = [np.mean(ll) for ll in lls_dict[key]]\n",
    "        avg_ll = np.mean(avg_lls_per_run)\n",
    "        std_ll = np.std(avg_lls_per_run)\n",
    "        if key == 'elbo':\n",
    "            print('Evaluating using ELBO..')\n",
    "        else:\n",
    "            print('Evaluating using ' + str(key) + ' bins..')\n",
    "        print('AVG LL: %f ' % avg_ll + ' STD LL: %f ' % std_ll)\n",
    "        print('Latex string: %.2f$\\\\pm$%.2f' % (avg_ll, std_ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if case of OOM issues, decrease the batch size\n",
    "batch_size = 128\n",
    "only_test = True\n",
    "\n",
    "n_elbo_mc_samples = 1_000\n",
    "seed_everything(42)\n",
    "\n",
    "for dataset_name in BINARY_DATASETS:\n",
    "    \n",
    "    _, valid, test = load_debd(dataset_name)\n",
    "    if not only_test:\n",
    "        valid_loader = DataLoader(valid, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size)\n",
    "    print('Evaluating ' + dataset_name + '..')\n",
    "    \n",
    "    if not only_test:\n",
    "        bmv_valid_lls_dict = {key: [] for key in keys}    \n",
    "    bmv_test_lls_dict = {key: [] for key in keys}\n",
    "        \n",
    "    exp_runs = 0\n",
    "    for folder in list(os.walk(repo_dir + '/logs/debd/vae/' + dataset_name)):\n",
    "        \n",
    "        if 'checkpoints' in folder[0]:\n",
    "            exp_runs += 1\n",
    "            for ckpt in folder[2]:\n",
    "                model = VAE.load_from_checkpoint(folder[0] + '/' + ckpt).to(device)\n",
    "                for key in keys:\n",
    "                    if isinstance(key, int):\n",
    "                        test_sampler.n_bins = key\n",
    "                        z, log_w = test_sampler(seed=42)\n",
    "\n",
    "                    if 'best_model_valid' in ckpt:\n",
    "                        if key == 'elbo':\n",
    "                            if not only_test:\n",
    "                                bmv_valid_lls_dict[key].append(\n",
    "                                    evaluate_elbo(model, valid_loader, n_elbo_mc_samples, device))\n",
    "                            bmv_test_lls_dict[key].append(\n",
    "                                evaluate_elbo(model, test_loader, n_elbo_mc_samples, device))\n",
    "                        else:\n",
    "                            if not only_test:\n",
    "                                bmv_valid_lls_dict[key].append(\n",
    "                                    evaluate_mixture(model, valid_loader, z, log_w, device))\n",
    "                            bmv_test_lls_dict[key].append(\n",
    "                                evaluate_mixture(model, test_loader, z, log_w, device))\n",
    "                            \n",
    "    if not only_test:\n",
    "        print('\\n --- BMV on VALID ---')\n",
    "        evaluate_lls_dict(bmv_valid_lls_dict)\n",
    "    print('\\n --- BMV on TEST ---')\n",
    "    evaluate_lls_dict(bmv_test_lls_dict)\n",
    "    \n",
    "    print('\\n' + str(exp_runs) + ' runs found and evaluated for ' + dataset_name + '\\n\\n')\n",
    "    print('---------------------------------------------------------------------------\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
