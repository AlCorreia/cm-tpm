{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79cd907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "repo_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(repo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ade8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.reproducibility import seed_everything\n",
    "from models.mixtures import BernoulliMixture\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.datasets import load_debd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "gpus = None if device == 'cpu' else 1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37550bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'nltcs'\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a402d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = load_debd(dataset_name)\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid, batch_size=batch_size, drop_last=True)\n",
    "print(dataset_name, train.shape, valid.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14e9fbe",
   "metadata": {},
   "source": [
    "## Instantiate mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "n_components = 1024\n",
    "model = BernoulliMixture(\n",
    "    logits_p=torch.randn(n_components, train.shape[1]),\n",
    "    logits_w=torch.full((n_components,), 1 / n_components),\n",
    "    learn_w=False\n",
    ").to(device)\n",
    "opt = torch.optim.Adam(params=model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81d7fb6",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee541fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_epochs = 150\n",
    "early_stopping_epochs = 30\n",
    "warmup = 30\n",
    "\n",
    "best_model = model\n",
    "best_loss = np.inf\n",
    "e = 0\n",
    "\n",
    "for epoch in range(max_num_epochs):\n",
    "    model.train()\n",
    "    train_loss_avg = []\n",
    "    for x in train_loader:\n",
    "        opt.zero_grad()\n",
    "        loss = -model(x.to(device)).mean()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss_avg.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss_avg = []\n",
    "    with torch.no_grad():\n",
    "        for x in valid_loader:\n",
    "            loss = -model(x.to(device)).mean()\n",
    "            valid_loss_avg.append(loss.item())\n",
    "    val_loss_epoch = np.mean(valid_loss_avg)\n",
    "    \n",
    "    # early-stopping\n",
    "    if val_loss_epoch < best_loss:\n",
    "        e = 0\n",
    "        best_loss = val_loss_epoch\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_model_epoch = epoch\n",
    "    else:\n",
    "        e += 1\n",
    "        if epoch < warmup:\n",
    "            e = 0\n",
    "        if e > early_stopping_epochs:\n",
    "            break\n",
    "\n",
    "    print('Epoch [%d / %d] Training loss: %f Validation Loss: %f e: %d' % \n",
    "          (epoch + 1, max_num_epochs, np.mean(train_loss_avg), val_loss_epoch, e))\n",
    "\n",
    "print('Best model epoch: ', best_model_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c1249b",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c727ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you use a high number number of bins then you may want to decrease the batch size\n",
    "test_loader = DataLoader(test, batch_size=16, drop_last=False)\n",
    "\n",
    "test_ll = []\n",
    "model.eval()\n",
    "for x in tqdm(test_loader):\n",
    "    test_ll.extend(list(model(x.to(device)).detach().cpu().numpy()))\n",
    "assert len(test_ll) == test.shape[0]\n",
    "print('Test LL: %.2f' % np.mean(test_ll))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
